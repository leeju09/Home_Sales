# Home_Sales

The objective of this challenge was to leverage SparkSQL for analyzing "big data" to extract key metrics from home sales data.

Skills demonstrated:

- Utilized PySpark to read data from an AWS S3 bucket and convert a CSV file into a DataFrame.

- Created a temporary view to execute SparkSQL queries.

- Wrote and ran SparkSQL queries.

- Employed Spark to partition data, cache and uncache a temporary table, and confirmed that the table had been uncached.

- Compared query execution times across different methods (caching, partitioning, and using Parquet files).

- Used Google Colab to run PySpark.


Resources:
************
The resources used to complete this challenge included in-class activities, Stack Overflow, and Xpert Learning Assistant.